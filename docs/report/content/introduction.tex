\section{Introduction}

Legal implementations on handling hate speech is different from one country to another. While hate speech is not prohibited in the United States due to the \textit{freedom of speech}, other countries - especially in the European Union - can sue hate speech actors for either offending the public order or human dignity. While being able to prosecute actors in public without much effort, the internet and especially social media platforms provide an easy and anonymous way to practice hate speech without legal consequence enforcements. Several steps were taken to tackle hate speech online, one of them being the \textit{code of conduct} on countering illegal hate speech online, an initiative of the european commission in close collaboration with major IT companies like \textit{Facebook}, \textit{Microsoft}, \textit{Twitter} and \textit{YouTube} \cite{EuropeanCommission.20200622}. While respecting the freedom of speech, these companies commit to delete hate speech contributions within 24 hours of the initial deletion request. 

To further automize the process of detecting hate speech contributions, several text analytics approaches have been evaluated in the recent past. Many of them are using methods of \textit{natural language processing} and \textit{deep learning} for hate speech detection and rely on meaningful features being learned automatically by deep neural networks instead of using hand-crafted features. One of the most common approaches is to use uni- and bidirectional long short-term memory (LSTM) networks, a recurrent neural network ar\-chi\-tec\-tu\-re that can process input of arbitrary length and remembers context information \cite{Dorris2020, Syam2019, Saksesi2018}. The paper \cite{Founta2019} states, that even a simple gated recurrent unit (GRU) architecture can perform as good as more complex units. \cite{Saleh2020} repurposes the famous bidirectional encoder representations from transformers (BERT) language model to perform clas\-si\-fi\-ca\-tion tasks for hate speech detection. Besides that, other approaches use con\-vo\-lu\-tional neural networks (CNNs) to extract typical hate speech patterns \cite{Badjatiya2017, Roy2020, Kapil2020} or even deep belief network algorithms \cite{Muhammad2020}. Using neural network approaches means to automatically learn representative features for the classification task. On the other hand, the papers introduced in \autoref{related_work} use a different approach by solving the classification task with manually extracted features. Nevertheless, none of the papers combines the different achievements of such recent research and compares it to a baseline neural network architecture, which is what this work is dedicated to.

An introduction to the approach taken is given in \autoref{approach}. Therefore the term \enquote{hate speech} is defined. Based upon this, the data and the features are described. Finally different classifiers will be trained and evaluated on the holistic, hand-crafted feature set based on recent pub\-li\-ca\-tions in the field of hate speech detection. 
Experimental details, such as the building and pre\-pro\-cess\-ing of the training corpus as well as data insights are described in \autoref{experimental_setup}. The results of this work in \autoref{analysis} should show several statistical insights into typical hate speech artifacts, how the conventional classifiers performed compared to the neural network baseline and which features work best for which classifier. A summary over the achievements earned will be drawn in \autoref{conclusion}.

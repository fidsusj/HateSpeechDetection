\section*{Member contribution}

\subsubsection*{Christopher Klammt}

Main focus was the analysis of the preprocessed dataset and providing insights for the milestone, before extracting features. After feature extraction hate speech statistics were drawn out to show what signifies hate speech. Additionally, the semantic features and the SVM classifier were added. To handle the unbalanced dataset undersampling in the form of randomly deleting overrepresented instances and oversampling using synthetic generation of underrepresented instances (via SMOTE) was implemented.

Faced challenges when trying to provide meaningful insights into the hate speech statistics as a lot of features were count-based and e.g. did not contain the occurring laughing expression or PoS pattern. Furthermore, balancing the dataset did not fare well for performance and it was not possible to apply SMOTE for the neural network approach.

\subsubsection*{Felix Hausberger}

Took care of the data preparation and corpus building based on the two utilized datasets. Also setup the GitHub actions and hooks for CI. Added the Logistic Regression classifier and implemented a Word2Vec model. Furthermore, implemented the PoS pattern feature, as well as ngrams, sentiment based on VADER and a topic detection based on LDA. In the analysis had a close look at the feature importance for the different classifiers.

% TODO: text verbessern + challenges

\subsubsection*{Nils Krehl}

One major contribution was the development of the reusable pipeline for feature extraction and classifier execution. New features and classifiers can easily be added to the pipeline. As part of the pipeline the optimal hyperparameters are automatically learned by executing \textit{RandomizedSearchCV} and the classifier performance metrics are calculated automatically. Added Random Forest and Decision Tree classifiers as well as the neural network baseline via LSTM. Added some features such as TF-IDF, dictionaries and special characters.

Faced challenges in optimizing the execution time of the classifier pipeline, which made the change from \textit{GridSearchCV} to \textit{RandomizedSearchCV} and the use of multiprocessing necessary. Through both measures, it was possible to reduce the execution time to around 10min. 

\section{Conclusion} \label{conclusion}

Coming to a conclusion, our main research question was whether conventional machine learning approaches combined with suitable features can outperform neural network based approaches. The short answer to this is, that the classical machine learning methods based on our hand-crafted feature set is definitely able to compete with our neural network baseline. For the unbalanced dataset the LSTM baseline only slightly - and rather insignificantly - outperforms the different classical methods, which all perform quite similarly. They also perform quite well with an F1-score around 93\%. But it is important to note, that we used grid search to optimize these methods by tuning the hyperparameters, so there is not much room for improvement. For our neural network approach this does not hold true, as we only used a basic implementation without much fine-tuning or testing different network architectures.

Furthermore, while answering this research question we also created a solid hand-crafted feature set based on recent publications. And we developed an easily extendible pipeline incorporating the preprocessing of the underlying data as well as making it easy to add more features and classifiers.

Another finding of our work is the insights into the hate speech statistics and feature importance which lets us have a look at what hate speech is "made" of and indicators for it. The most important features are sentiment and unigram features, with a few words that clearly indicate hate.

\vspace{0.5cm}

As an outlook, there are some improvements and further investigations we would like to evaluate in future work. For one it should be very interesting to expand the currently binary classification into hate speech and non-hate speech to a ternary classification. As this makes the classification more complex this should be easier to achieve with neural network architectures, but it may be interesting to further evaluate the boundaries of the conventional machine learning classifiers.
As already mentioned, the hyperparameter tuning for the SVM was not as extensive as it could be, so there might be room for improvement here.
Additionally, the gained knowledge from the analysis of the hate speech statistics could help to further improve hate speech patterns based on PoS-tags to achieve better results and a more clear differentiation between hate speech and non-hate speech posts.
One could also implement google's bad word list as a separate feature, similar to the hate speech dictionary.

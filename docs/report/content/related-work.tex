\newpage
\section{Related Work} \label{related_work}

As the goal of this work is to solve a hate speech classification problem with manually extracted features, recent work was evaluated proposing different feature sets for this task. 

\cite{Watanabe2018} categorizes features into four different groups. Sentiment-based features give information about the polarity of a document, which is important as many hate speech documents stand out by being mostly negativ. Sentiment features count the occurences of punctuations, capitalized words, interjections, etc. A dictionary of typical hate speech words can be obtained by extracting most common unigrams from a given corpus uilding thr unigram features. Pattern features represent the last feature group containing common syntactic patterns based on PoS tags. The apporach presented in this paper achieved an accuracy of 87.4\% using combined features from these four groups. The classifiers used were SVM, Random Forest and J48graft.

\cite{Oriola2020} concludes character n-grams, word n-grams, negative sentiment-based scores and syntactic-based features as a decent feature set to train classifiers on. Watching at the results, an optimized support vector machine with character n-grams performed best with 0.894 TPR, while optimized gradient boosting performed best with word n-grams, giving a 0.867 TPR. 

\cite{Fortuna2018} divides features into generic text mining features and specific hate speech detection features. Typical generic text mining features are dictionaries of insults typical for heate speech, swear words, profane words verbal abuse, etc., n-grams, lexical syntactic based template features, that capture grammatical dependencies within a sentence, topic classifications with latent dirichlet allocation, or sentiment polarity scores. On the other hand specific hate speech detection features do not rely on common abstract concepts known in the field of text analytics, but come with purpose built frameworks to detect these featues. Using the Stanford lexical parser along with a context-free lexical parsing model one can identify othering language which used a lot in hate speech. Other examples of specific hate speech features are the objectivity-subjectivity relations of the language as hate speech is more related to subjective communication, focus on particular stereotypes, intersectionism of oppression or declarations of superiority of the ingroup. 

Other related work like \cite{Gaydhani2018}, \cite{Malmasi2017} and \cite{ThomasDavidson2020} once more stress the importance of word and character n-grams for hate speech detection tasks. \cite{ThomasDavidson2020} even uses count indicators for hashtags, mentions, retweets and URLs and is esspecially important as a part of the dataset used in this work originated from the project behind this paper. The best performing model achieved 0.91\% overall precision, 0.9\% recall and a 0.9 F1-score, but the model is biased towards classifying tweets as less hateful or offensive than the human supervisors. 

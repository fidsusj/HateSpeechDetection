\newpage
\section{Related Work} \label{related_work}

As the goal of this work is to solve a hate speech classification problem with manually extracted features, recent work was evaluated proposing different feature sets for this task. 

\cite{Watanabe2018} categorizes features into four different groups. Sentiment-based fea\-tures give information about the polarity of a document, which is important as many hate speech documents stand out by being mostly negative. Sentiment features count the occurrences of punctuations, capitalized words, interjections, etc. A dictionary of typical hate speech words can be obtained by extracting most common unigrams from a given corpus building the unigram features. Pattern features represent the last feature group containing common syntactic patterns based on PoS tags. The approach presented in this paper achieved an accuracy of 87.4\% using combined features from these four groups. The classifiers used were SVM, Random Forest and J48graft.

\cite{Oriola2020} concludes character n-grams, word n-grams, negative sentiment-based scores and syntactic-based features as a decent feature set to train classifiers on. Looking at the results, an optimized support vector machine with character n-grams performed best with 0.894 TPR, while optimized gradient boosting performed best with word n-grams, giving a 0.867 TPR. 

\cite{Fortuna2018} divides features into generic text mining features and specific hate speech detection features. Typical generic text mining features are dictionaries of insults typical for hate speech, swear words, profane words, verbal abuse etc., n-grams, lexical syntactic based template features, that capture gram\-mat\-i\-cal dependencies within a sentence, topic classifications with latent dirich\-let allocation, or sentiment polarity scores. On the other hand specific hate speech detection features do not rely on common abstract concepts known in the field of text analytics, but come with purpose built frameworks to detect these features. Using the Stanford lexical parser along with a context-free lexical parsing model one can identify language which is used a lot in hate speech. Other examples of specific hate speech features are the objectivity-subjectivity relations of the language as hate speech is more related to subjective communication, focus on particular stereotypes, in\-ter\-sec\-tion\-ism of oppression or declarations of superiority of the in-group. 

Other related work like \cite{Gaydhani2018}, \cite{Malmasi2017} and \cite{ThomasDavidson2020} once more stress the importance of word and character n-grams for hate speech detection tasks. \cite{ThomasDavidson2020} even uses count indicators for hashtags, mentions, retweets and URLs and is especially important as a part of the dataset used in this work originated from the project behind this paper. The best performing model achieved 91\% overall precision, 90\% recall and a 90\% F1-score, but the model is biased towards classifying tweets as less hateful or offensive than the human supervisors. 

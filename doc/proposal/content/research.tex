\section{Research Topic Summary}

The main contribution of this work should be to evaluate the boundaries of conventional text analytics approaches for hate speech detection including manual feature extraction and subsequent text classification of documents into hate speech and non hate speech as opposed to modern deep learning approaches. The results should show which features work best for which classifier and which problems can be addressed with conventional text analytics methods and which not. A comparison to modern deep learning approaches should be drawn using the metrics of simple accuracy as well as precision and recall, respectively the F1-score. 

\newpage
\noindent
In order to achieve the goals of this work three milestones were identified: 

\begin{enumerate}
	\item Data preparation and representation
	\item Feature extraction
	\item Text analytics classifier
\end{enumerate}

\noindent
The following sections introduce these three aspects.

\subsection{Data preparation and representation}

There are two data sets used for the project. The first one \cite{ThomasDavidson.2020} uses data from the \textit{Twitter API}. It consists of a sample of around 25k tweets that were identified as hate speech based on a previously composed hate speech lexicon without regarding context information. Subsequently, each document in the corpus got labeled with one of the three categories \textit{hate speech}, \textit{offensive language} or \textit{neutral}. Therefore the data set follows a classical ternary classification style. The workers were adviced to follow predefined definitions of each category and to take context information into consideration. Each tweet was coded by three or more workers. The majority of tweets were classified as offensive language (76\% at 2/3, 53\% at 3/3), only 5\% were coded as hate speech. The data is provided offline as a CSV or pickle file. 

\noindent
The second data set uses data from the \textit{White Supremacy Forum} \cite{OnadeGibert.2020}. One document represents a sentence that is according to binary classification either labeled as hate or no hate. In total, 1.119 sentences containing hate and 8.537 sentences containing no hate are provided. Once again the documents were labeled manually by human actors following previously specified guidelines, on request additional context information were provided. 

\noindent
Both data sets are stated to be balanced, multiple documents cannot be traced back to a single user. In case of imbalanced distributions classifications can be less performant and accurate \cite{Oriola.2020}.

\subsection{Feature extraction}

There are two approaches for detecting hate speech, either using statistical and probabilistic methods from a conventional text analytics background or using deep learning based approaches. One main difference between the two approaches is the process of feature extraction. In deep learning approaches the used features are learned automatically, whereas classical text analytics techniques require a manual feature extraction process.

\noindent
The following list provides an overview of possible features and their technical methods from the area of text analytics. The list is clustered into the four categories based on Watanabe, Bouazizi and Ohtsuki \cite{Watanabe.2018}. The possible text analytics approaches derive from the literature review of Fortuna and Nunes \cite{Fortuna.2018}.
\begin{itemize}
	\item \textbf{Sentiment-based features}: Is the tweet rather positive or negative? \newline
	% allow us to extract the polarity of the tweet
	Text analytics approaches: Dictionaries, Rule Based Approaches, Ob\-jec\-ti\-vi\-ty-Subjectivity of the Language, Declarations of Superiority of the Ingroup \cite{Fortuna.2018}
	\item \textbf{Semantic features}: Which parts of the tweet are emphasized? \newline
	% allow us to find any emphasized expression
	Text analytics approaches: TF-IDF, Part-of-speech, Profanity Windows, Lexical Syntactic Feature-based, Topic Classification, Template Based Strategy, Word Sense Disambiguation Techniques, Othering Language \cite{Fortuna.2018}
	\item \textbf{Unigram features}: Are there any specific words marking hate speech? \newline
	% allow us to detect any explicit form of hate speech
	Text analytics approaches: N-grams, Bag-of-words \cite{Fortuna.2018}
	\item \textbf{Pattern features}: Are there any specific patterns marking hate speech? \newline
	% allow the identification of any longer or implicit forms of hate speech
	Text analytics approaches: Part-of-speech, Dictionaries, Typed De\-pen\-den\-cies,Word Embeddings \cite{Fortuna.2018}
\end{itemize}


\subsection{Text analytics approach}

Current research in the area of hate speech detection is often built upon deep learning techniques. Exemplary therefore are the works of Roy et al. \cite{Roy.2020}, Setyadi, Nasrun and Setianingsih \cite{NabiilaAdaniSetyadi.2018} and Kapil, Ekbal and Das \cite{Kapil.2020}, to name just a few examples. Among other metrics by considering the accuracy one can evaluate the success of a choosen approach. Roy et al. \cite{Roy.2020} have reached accuracies up to 95\% for detecting whether a tweet is hateful or not.

\noindent
Nevertheless even classical machine learning techniques such as Support Vector Machines (SVM) combined with text analytics methods are a promis\-ing approach.
Watanabe, Bouazizi and Ohtsuki \cite{Watanabe.2018} used a decision tree and reached an accuracy of 87.4\%.

% TODO: Describe Classificators
\noindent
Furthermore the results of classical machine learning techniques can be used as reference value to evaluate the deep learning approach. This was done by Roy et al. \cite{Roy.2020}.
